{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Python Programming: Ridge Regression: Brian onyango --4/20/2022","provenance":[{"file_id":"1Ze7NdeEjdsnXENNWdpCfo7oJwcjyDfBb","timestamp":1650464699615}],"collapsed_sections":["qa33QGdE1vQe","hTqFcUIQuO_3","kke3w5L512WF","3-BreaBg2FdS","AMM6ePT52H0Z","CfPAQs0M2Jwi","0-cyo-cG2MOs"],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"0J6i3jHftz7H"},"source":["<font color=\"green\">*To start working on this notebook, or any other notebook that we will use in the Moringa Data Science Course, we will need to save our own copy of it. We can do this by clicking File > Save a Copy in Drive. We will then be able to make edits to our own copy of this notebook.*</font>"]},{"cell_type":"markdown","metadata":{"id":"1gdLmzAE1NRn"},"source":["# Python Programming: Ridge Regression"]},{"cell_type":"markdown","metadata":{"id":"qa33QGdE1vQe"},"source":["## 1.0 Example "]},{"cell_type":"code","metadata":{"id":"uqjexWue1I72","executionInfo":{"status":"ok","timestamp":1650518409423,"user_tz":-180,"elapsed":19,"user":{"displayName":"Brian Onyango","userId":"15608923775886601750"}}},"source":["# Example \n","# ---\n","# Regularization is the process of penalizing coefficients of variables either by removing them and or reducing their impact. \n","# Ridge regression reduces the effect of problematic variables close to zero but never fully removes them. \n","# ---\n","# Question: Build a regrssion model to predict expenses based on the variables available.\n","# ---\n","# Dataset source: Pydataset Library: VietNamI Dataset\n","# ---\n","#"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"b3Lmc0ijk7qS","executionInfo":{"status":"ok","timestamp":1650518410480,"user_tz":-180,"elapsed":1073,"user":{"displayName":"Brian Onyango","userId":"15608923775886601750"}}},"source":["# Importing our libraries\n","# \n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.linear_model import Ridge\n","from sklearn.linear_model import LinearRegression\n","from sklearn.metrics import mean_squared_error"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"JNS5ONaGk88J","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650518428581,"user_tz":-180,"elapsed":18110,"user":{"displayName":"Brian Onyango","userId":"15608923775886601750"}},"outputId":"f17960b4-63bd-41de-ab10-fe69fb8c7f02"},"source":["# installing !pip install pydataset and importing pydataset so as to use a dataset from the package\n","# \n","!pip install pydataset\n","from pydataset import data "],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pydataset\n","  Downloading pydataset-0.2.0.tar.gz (15.9 MB)\n","\u001b[K     |████████████████████████████████| 15.9 MB 486 kB/s \n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from pydataset) (1.3.5)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->pydataset) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->pydataset) (2022.1)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.7/dist-packages (from pandas->pydataset) (1.21.6)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->pydataset) (1.15.0)\n","Building wheels for collected packages: pydataset\n","  Building wheel for pydataset (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pydataset: filename=pydataset-0.2.0-py3-none-any.whl size=15939432 sha256=3fea787222291058dd2350b18fd58f66218ff3a45c4a49364f817db5471a8e24\n","  Stored in directory: /root/.cache/pip/wheels/32/26/30/d71562a19eed948eaada9a61b4d722fa358657a3bfb5d151e2\n","Successfully built pydataset\n","Installing collected packages: pydataset\n","Successfully installed pydataset-0.2.0\n","initiated datasets repo at: /root/.pydataset/\n"]}]},{"cell_type":"code","metadata":{"id":"Qiv1NUe2qDaK","executionInfo":{"status":"ok","timestamp":1650518429020,"user_tz":-180,"elapsed":449,"user":{"displayName":"Brian Onyango","userId":"15608923775886601750"}}},"source":["# Data Preparation\n","# \n","\n","# Loading the data and convert the sex variable to a dummy variable\n","#\n","df = pd.DataFrame(data('VietNamI'))\n","\n","# Transforming categorical data to numeric\n","df.loc[df.sex== 'male','sex'] = 0\n","df.loc[df.sex== 'female','sex'] = 1\n","df['sex'] = df['sex'].astype(int)\n","\n","# Setting up our X and y datasets\n","#\n","X = df[['pharvis','age','sex','married','educ','illness','injury','illdays','actdays','insurance']]\n","y = df['lnhhexp']"],"execution_count":4,"outputs":[]},{"cell_type":"code","source":["df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"2rqKFEXe9dWo","executionInfo":{"status":"ok","timestamp":1650518429023,"user_tz":-180,"elapsed":50,"user":{"displayName":"Brian Onyango","userId":"15608923775886601750"}},"outputId":"0d6a0924-d011-4c4b-e02a-5b5f4da8534d"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   pharvis   lnhhexp       age  sex  married  educ  illness  injury  illdays  \\\n","1        0  2.730363  3.761200    0        1     2        1       0        7   \n","2        0  2.737248  2.944439    1        0     0        1       0        4   \n","3        0  2.266935  2.564950    0        0     4        0       0        0   \n","4        1  2.392753  3.637586    1        1     3        1       0        3   \n","5        1  3.105335  3.295837    0        1     3        1       0       10   \n","\n","   actdays  insurance  commune  \n","1        0          0      192  \n","2        0          0      167  \n","3        0          1       76  \n","4        0          1      123  \n","5        0          0      148  "],"text/html":["\n","  <div id=\"df-4fc6a73d-256c-4b87-85e5-d23759e462b3\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>pharvis</th>\n","      <th>lnhhexp</th>\n","      <th>age</th>\n","      <th>sex</th>\n","      <th>married</th>\n","      <th>educ</th>\n","      <th>illness</th>\n","      <th>injury</th>\n","      <th>illdays</th>\n","      <th>actdays</th>\n","      <th>insurance</th>\n","      <th>commune</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>2.730363</td>\n","      <td>3.761200</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>7</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>192</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>2.737248</td>\n","      <td>2.944439</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>167</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>2.266935</td>\n","      <td>2.564950</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>76</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>2.392753</td>\n","      <td>3.637586</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>123</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>1</td>\n","      <td>3.105335</td>\n","      <td>3.295837</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>10</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>148</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4fc6a73d-256c-4b87-85e5-d23759e462b3')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-4fc6a73d-256c-4b87-85e5-d23759e462b3 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-4fc6a73d-256c-4b87-85e5-d23759e462b3');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"nNhuD8WJqGFb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650518429026,"user_tz":-180,"elapsed":40,"user":{"displayName":"Brian Onyango","userId":"15608923775886601750"}},"outputId":"3acc05be-470b-4ebd-c865-457720662149"},"source":["# Creating our baseline regression model\n","# This is a model that has no regularization to it\n","# \n","regression = LinearRegression()\n","regression.fit(X,y)\n","first_model = (mean_squared_error(y_true=y,y_pred=regression.predict(X)))\n","print(first_model)\n","\n","# The output  value of 0.355289 will be our indicator to determine if the regularized ridge regression model is superior or not."],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["0.35528915032173053\n"]}]},{"cell_type":"code","metadata":{"id":"HaImX3JnqN4o","executionInfo":{"status":"ok","timestamp":1650518429030,"user_tz":-180,"elapsed":34,"user":{"displayName":"Brian Onyango","userId":"15608923775886601750"}}},"source":["# In order to create our ridge model we need to first determine the most appropriate value for the l2 regularization. \n","# L2 is the name of the hyperparameter that is used in ridge regression. \n","# Determining the value of a hyperparameter requires the use of a grid. \n","# In the code below, we first create our ridge model and indicate normalization in order to get better estimates. \n","# Next we setup the grid that we will use. \n","# The search object has several arguments within it. Alpha is hyperparameter we are trying to set. \n","# The log space is the range of values we want to test. \n","# We want the log of -5 to 2, but we only get 8 values from within that range evenly spread out. \n","# Are metric is the mean squared error. Refit set true means to adjust the parameters while modeling \n","# and cv is the number of folds to develop for the cross-validation. \n","#\n","ridge = Ridge(normalize=True)\n","search = GridSearchCV(estimator=ridge,param_grid={'alpha':np.logspace(-5,2,8)},scoring='neg_mean_squared_error',n_jobs=1,refit=True,cv=10)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"LrLMVyuEqSnv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650518431334,"user_tz":-180,"elapsed":2336,"user":{"displayName":"Brian Onyango","userId":"15608923775886601750"}},"outputId":"5b5d565b-e42a-4f21-e0d1-a41ea5093903"},"source":["# We now use the .fit function to run the model and then use the .best_params_ and\n","#  .best_scores_ function to determine the models strength. \n","# \n","search.fit(X,y)\n","search.best_params_\n","{'alpha': 0.01}\n","abs(search.best_score_) \n","\n","# The best_params_ tells us what to set alpha too which in this case is 0.01. \n","# The best_score_ tells us what the best possible mean squared error is. \n","# In this case, the value of 0.38 is worse than what the baseline model was. "],"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n"]},{"output_type":"execute_result","data":{"text/plain":["0.38013256937541345"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"VqifjT6IqUx1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650518431336,"user_tz":-180,"elapsed":37,"user":{"displayName":"Brian Onyango","userId":"15608923775886601750"}},"outputId":"ff2f49f6-e476-4edc-fbe8-4e049e994227"},"source":["# We can confirm this by fitting our model with the ridge information and finding the mean squared error below\n","#\n","ridge = Ridge(normalize=True,alpha=0.01)\n","ridge.fit(X,y)\n","second_model = (mean_squared_error(y_true=y,y_pred=ridge.predict(X)))\n","print(second_model)"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["0.3552932199260658\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n"]}]},{"cell_type":"code","metadata":{"id":"RJ_jJd7WqchO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650518431338,"user_tz":-180,"elapsed":28,"user":{"displayName":"Brian Onyango","userId":"15608923775886601750"}},"outputId":"41f63374-df37-4003-cc95-602fbcb068dc"},"source":["# The 0.35 is lower than the 0.38. This is because the last results are not cross-validated. \n","# In addition, these results indicate that there is little difference between the ridge and baseline models. \n","# This is confirmed with the coefficients of each model found below.\n","# \n","coef_dict_baseline = {}\n","for coef, feat in zip(regression.coef_,data(\"VietNamI\").columns):\n","    coef_dict_baseline[feat] = coef\n","coef_dict_baseline\n","\n","# The coefficient values are about the same. This means that the penalization made little difference with this dataset."],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'actdays': 0.14687843649771123,\n"," 'age': 0.004012412278795818,\n"," 'educ': -0.06180921300600299,\n"," 'illdays': -0.0067170633108930965,\n"," 'illness': 0.040870384578962464,\n"," 'injury': -0.00276376871656904,\n"," 'lnhhexp': 0.06480086550467884,\n"," 'married': 0.07527646383836208,\n"," 'pharvis': 0.01328205088695085,\n"," 'sex': -0.08739614349708981}"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"hTqFcUIQuO_3"},"source":["## 2.0 Challenges"]},{"cell_type":"markdown","metadata":{"id":"kke3w5L512WF"},"source":["### <font color=\"green\">Challenge 1</font>"]},{"cell_type":"code","metadata":{"id":"Oo4qdt_F10I1","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1650518432025,"user_tz":-180,"elapsed":708,"user":{"displayName":"Brian Onyango","userId":"15608923775886601750"}},"outputId":"32febd34-80ad-4f5f-a508-040bc6bc1041"},"source":["# Challenge 1 \n","# ---\n","# Question: Build an accurate model that can estimate the weight of fish given the following dataset.\n","# ---\n","# Dataset url = http://bit.ly/FishDataset\n","# ---\n","url = 'http://bit.ly/FishDataset'\n","df = pd.read_csv(url)\n","df.head()"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["  Species  Weight  Length1  Length2  Length3   Height   Width\n","0   Bream   242.0     23.2     25.4     30.0  11.5200  4.0200\n","1   Bream   290.0     24.0     26.3     31.2  12.4800  4.3056\n","2   Bream   340.0     23.9     26.5     31.1  12.3778  4.6961\n","3   Bream   363.0     26.3     29.0     33.5  12.7300  4.4555\n","4   Bream   430.0     26.5     29.0     34.0  12.4440  5.1340"],"text/html":["\n","  <div id=\"df-0e224eb0-098d-4629-a481-7538bdfc0b95\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Species</th>\n","      <th>Weight</th>\n","      <th>Length1</th>\n","      <th>Length2</th>\n","      <th>Length3</th>\n","      <th>Height</th>\n","      <th>Width</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Bream</td>\n","      <td>242.0</td>\n","      <td>23.2</td>\n","      <td>25.4</td>\n","      <td>30.0</td>\n","      <td>11.5200</td>\n","      <td>4.0200</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Bream</td>\n","      <td>290.0</td>\n","      <td>24.0</td>\n","      <td>26.3</td>\n","      <td>31.2</td>\n","      <td>12.4800</td>\n","      <td>4.3056</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Bream</td>\n","      <td>340.0</td>\n","      <td>23.9</td>\n","      <td>26.5</td>\n","      <td>31.1</td>\n","      <td>12.3778</td>\n","      <td>4.6961</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Bream</td>\n","      <td>363.0</td>\n","      <td>26.3</td>\n","      <td>29.0</td>\n","      <td>33.5</td>\n","      <td>12.7300</td>\n","      <td>4.4555</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Bream</td>\n","      <td>430.0</td>\n","      <td>26.5</td>\n","      <td>29.0</td>\n","      <td>34.0</td>\n","      <td>12.4440</td>\n","      <td>5.1340</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0e224eb0-098d-4629-a481-7538bdfc0b95')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-0e224eb0-098d-4629-a481-7538bdfc0b95 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-0e224eb0-098d-4629-a481-7538bdfc0b95');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["# Setting up our X and y datasets\n","#\n","X = df[['Length1','Length2','Length3','Height','Width']]\n","y = df['Weight']"],"metadata":{"id":"J6wGDqRn84ST","executionInfo":{"status":"ok","timestamp":1650518432029,"user_tz":-180,"elapsed":36,"user":{"displayName":"Brian Onyango","userId":"15608923775886601750"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# Creating our baseline regression model\n","# This is a model that has no regularization to it\n","\n","regression = LinearRegression()\n","regression.fit(X,y)\n","first_model = (mean_squared_error(y_true=y,y_pred=regression.predict(X)))\n","print(first_model)\n","\n","# The output  value of 14607.87 will be our indicator to determine if the regularized ridge regression model is superior or not."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2ZJeY1fT9Pgh","executionInfo":{"status":"ok","timestamp":1650518432031,"user_tz":-180,"elapsed":35,"user":{"displayName":"Brian Onyango","userId":"15608923775886601750"}},"outputId":"3c97b14e-d943-4267-9c9d-1c28d6697f40"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["14607.878944541946\n"]}]},{"cell_type":"code","source":["y_pred=regression.predict(X)\n","comparison_frame = pd.DataFrame({'Actual': y, 'Predicted': y_pred})\n","comparison_frame"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"4BrvwYfWAXbC","executionInfo":{"status":"ok","timestamp":1650518432033,"user_tz":-180,"elapsed":29,"user":{"displayName":"Brian Onyango","userId":"15608923775886601750"}},"outputId":"29bc3654-4f9b-42c3-dcea-1747f17c3c4e"},"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["     Actual    Predicted\n","0     242.0   326.816128\n","1     290.0   369.578593\n","2     340.0   370.824180\n","3     363.0   439.056139\n","4     430.0   444.169168\n","5     450.0   466.125319\n","6     500.0   496.151343\n","7     390.0   473.623986\n","8     450.0   511.951893\n","9     500.0   540.445456\n","10    475.0   536.530408\n","11    500.0   551.801795\n","12    500.0   540.315043\n","13    340.0   556.058646\n","14    600.0   584.399821\n","15    600.0   607.280498\n","16    700.0   608.214933\n","17    700.0   602.630160\n","18    610.0   645.876879\n","19    650.0   629.752138\n","20    575.0   636.947597\n","21    685.0   671.896588\n","22    620.0   645.001061\n","23    680.0   651.903313\n","24    700.0   670.712639\n","25    725.0   666.680273\n","26    720.0   688.737134\n","27    714.0   698.767300\n","28    850.0   720.439783\n","29   1000.0   796.130106\n","30    920.0   803.629248\n","31    955.0   807.543307\n","32    925.0   867.359645\n","33    975.0   911.564381\n","34    950.0   894.459746\n","35     40.0   -89.132406\n","36     69.0    34.595735\n","37     78.0    76.616700\n","38     87.0    91.944858\n","39    120.0   141.523358\n","40      0.0   148.118452\n","41    110.0   135.977720\n","42    120.0   132.181820\n","43    150.0   160.549023\n","44    145.0   197.221870\n","45    160.0   182.361043\n","46    140.0   197.436547\n","47    160.0   210.102287\n","48    169.0   225.465746\n","49    161.0   221.791462\n","50    200.0   249.243621\n","51    180.0   286.003189\n","52    290.0   331.924936\n","53    272.0   344.599081\n","54    390.0   505.821099\n","55    270.0   301.848807\n","56    270.0   305.717655\n","57    306.0   373.555113\n","58    540.0   539.812477\n","59    800.0   695.313060\n","60   1000.0   798.775738\n","61     55.0    13.382832\n","62     60.0    23.996809\n","63     90.0    96.179087\n","64    120.0   152.418931\n","65    150.0   192.669433\n","66    140.0   192.277599\n","67    170.0   219.174948\n","68    145.0   241.654051\n","69    200.0   298.443787\n","70    273.0   365.570457\n","71    300.0   402.318557\n","72      5.9  -250.771870\n","73     32.0   -91.487008\n","74     40.0   -38.541628\n","75     51.5    19.850421\n","76     70.0    24.772853\n","77    100.0    58.209999\n","78     78.0    80.138449\n","79     80.0    90.611112\n","80     85.0    92.293575\n","81     85.0   101.295452\n","82    110.0   135.985675\n","83    115.0   136.790436\n","84    125.0   138.513922\n","85    130.0   163.122027\n","86    120.0   171.287250\n","87    120.0   160.628108\n","88    130.0   173.927864\n","89    135.0   167.277986\n","90    110.0   167.865624\n","91    130.0   182.366315\n","92    150.0   208.852636\n","93    145.0   190.612106\n","94    150.0   177.772822\n","95    170.0   223.294953\n","96    225.0   265.457832\n","97    145.0   241.773140\n","98    188.0   272.752538\n","99    180.0   267.220590\n","100   197.0   295.891086\n","101   218.0   369.565140\n","102   300.0   411.502604\n","103   260.0   366.126641\n","104   265.0   362.855467\n","105   250.0   374.593643\n","106   250.0   395.072084\n","107   300.0   435.575171\n","108   320.0   443.591862\n","109   514.0   620.344963\n","110   556.0   644.929996\n","111   840.0   716.129670\n","112   685.0   712.401600\n","113   700.0   725.520568\n","114   700.0   713.933165\n","115   690.0   717.912893\n","116   900.0   803.687332\n","117   650.0   770.193116\n","118   820.0   846.270847\n","119   850.0   809.693402\n","120   900.0   807.169159\n","121  1015.0   833.822861\n","122   820.0   783.196139\n","123  1100.0   880.140869\n","124  1000.0   890.724522\n","125  1100.0   920.257727\n","126  1000.0   927.610354\n","127  1000.0   947.516165\n","128   200.0   383.563510\n","129   300.0   412.932325\n","130   300.0   451.291299\n","131   300.0   539.966400\n","132   430.0   599.581488\n","133   345.0   574.212030\n","134   456.0   699.687280\n","135   510.0   689.879591\n","136   540.0   726.408225\n","137   500.0   739.348570\n","138   567.0   810.288812\n","139   770.0   832.640293\n","140   950.0   966.667240\n","141  1250.0  1103.888589\n","142  1600.0  1152.752481\n","143  1550.0  1152.752481\n","144  1650.0  1265.843019\n","145     6.7  -224.382326\n","146     7.5  -199.398436\n","147     7.0  -200.969515\n","148     9.7  -178.047479\n","149     9.8  -177.758950\n","150     8.7  -180.772783\n","151    10.0  -160.733438\n","152     9.9  -163.383041\n","153     9.8  -162.017600\n","154    12.2  -160.608116\n","155    13.4  -145.535439\n","156    12.2  -137.843413\n","157    19.7   -83.279758\n","158    19.9   -82.005694"],"text/html":["\n","  <div id=\"df-a87215cb-55d9-4ee7-8ef0-79020e33666d\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Actual</th>\n","      <th>Predicted</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>242.0</td>\n","      <td>326.816128</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>290.0</td>\n","      <td>369.578593</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>340.0</td>\n","      <td>370.824180</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>363.0</td>\n","      <td>439.056139</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>430.0</td>\n","      <td>444.169168</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>450.0</td>\n","      <td>466.125319</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>500.0</td>\n","      <td>496.151343</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>390.0</td>\n","      <td>473.623986</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>450.0</td>\n","      <td>511.951893</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>500.0</td>\n","      <td>540.445456</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>475.0</td>\n","      <td>536.530408</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>500.0</td>\n","      <td>551.801795</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>500.0</td>\n","      <td>540.315043</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>340.0</td>\n","      <td>556.058646</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>600.0</td>\n","      <td>584.399821</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>600.0</td>\n","      <td>607.280498</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>700.0</td>\n","      <td>608.214933</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>700.0</td>\n","      <td>602.630160</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>610.0</td>\n","      <td>645.876879</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>650.0</td>\n","      <td>629.752138</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>575.0</td>\n","      <td>636.947597</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>685.0</td>\n","      <td>671.896588</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>620.0</td>\n","      <td>645.001061</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>680.0</td>\n","      <td>651.903313</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>700.0</td>\n","      <td>670.712639</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>725.0</td>\n","      <td>666.680273</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>720.0</td>\n","      <td>688.737134</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>714.0</td>\n","      <td>698.767300</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>850.0</td>\n","      <td>720.439783</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>1000.0</td>\n","      <td>796.130106</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>920.0</td>\n","      <td>803.629248</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>955.0</td>\n","      <td>807.543307</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>925.0</td>\n","      <td>867.359645</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>975.0</td>\n","      <td>911.564381</td>\n","    </tr>\n","    <tr>\n","      <th>34</th>\n","      <td>950.0</td>\n","      <td>894.459746</td>\n","    </tr>\n","    <tr>\n","      <th>35</th>\n","      <td>40.0</td>\n","      <td>-89.132406</td>\n","    </tr>\n","    <tr>\n","      <th>36</th>\n","      <td>69.0</td>\n","      <td>34.595735</td>\n","    </tr>\n","    <tr>\n","      <th>37</th>\n","      <td>78.0</td>\n","      <td>76.616700</td>\n","    </tr>\n","    <tr>\n","      <th>38</th>\n","      <td>87.0</td>\n","      <td>91.944858</td>\n","    </tr>\n","    <tr>\n","      <th>39</th>\n","      <td>120.0</td>\n","      <td>141.523358</td>\n","    </tr>\n","    <tr>\n","      <th>40</th>\n","      <td>0.0</td>\n","      <td>148.118452</td>\n","    </tr>\n","    <tr>\n","      <th>41</th>\n","      <td>110.0</td>\n","      <td>135.977720</td>\n","    </tr>\n","    <tr>\n","      <th>42</th>\n","      <td>120.0</td>\n","      <td>132.181820</td>\n","    </tr>\n","    <tr>\n","      <th>43</th>\n","      <td>150.0</td>\n","      <td>160.549023</td>\n","    </tr>\n","    <tr>\n","      <th>44</th>\n","      <td>145.0</td>\n","      <td>197.221870</td>\n","    </tr>\n","    <tr>\n","      <th>45</th>\n","      <td>160.0</td>\n","      <td>182.361043</td>\n","    </tr>\n","    <tr>\n","      <th>46</th>\n","      <td>140.0</td>\n","      <td>197.436547</td>\n","    </tr>\n","    <tr>\n","      <th>47</th>\n","      <td>160.0</td>\n","      <td>210.102287</td>\n","    </tr>\n","    <tr>\n","      <th>48</th>\n","      <td>169.0</td>\n","      <td>225.465746</td>\n","    </tr>\n","    <tr>\n","      <th>49</th>\n","      <td>161.0</td>\n","      <td>221.791462</td>\n","    </tr>\n","    <tr>\n","      <th>50</th>\n","      <td>200.0</td>\n","      <td>249.243621</td>\n","    </tr>\n","    <tr>\n","      <th>51</th>\n","      <td>180.0</td>\n","      <td>286.003189</td>\n","    </tr>\n","    <tr>\n","      <th>52</th>\n","      <td>290.0</td>\n","      <td>331.924936</td>\n","    </tr>\n","    <tr>\n","      <th>53</th>\n","      <td>272.0</td>\n","      <td>344.599081</td>\n","    </tr>\n","    <tr>\n","      <th>54</th>\n","      <td>390.0</td>\n","      <td>505.821099</td>\n","    </tr>\n","    <tr>\n","      <th>55</th>\n","      <td>270.0</td>\n","      <td>301.848807</td>\n","    </tr>\n","    <tr>\n","      <th>56</th>\n","      <td>270.0</td>\n","      <td>305.717655</td>\n","    </tr>\n","    <tr>\n","      <th>57</th>\n","      <td>306.0</td>\n","      <td>373.555113</td>\n","    </tr>\n","    <tr>\n","      <th>58</th>\n","      <td>540.0</td>\n","      <td>539.812477</td>\n","    </tr>\n","    <tr>\n","      <th>59</th>\n","      <td>800.0</td>\n","      <td>695.313060</td>\n","    </tr>\n","    <tr>\n","      <th>60</th>\n","      <td>1000.0</td>\n","      <td>798.775738</td>\n","    </tr>\n","    <tr>\n","      <th>61</th>\n","      <td>55.0</td>\n","      <td>13.382832</td>\n","    </tr>\n","    <tr>\n","      <th>62</th>\n","      <td>60.0</td>\n","      <td>23.996809</td>\n","    </tr>\n","    <tr>\n","      <th>63</th>\n","      <td>90.0</td>\n","      <td>96.179087</td>\n","    </tr>\n","    <tr>\n","      <th>64</th>\n","      <td>120.0</td>\n","      <td>152.418931</td>\n","    </tr>\n","    <tr>\n","      <th>65</th>\n","      <td>150.0</td>\n","      <td>192.669433</td>\n","    </tr>\n","    <tr>\n","      <th>66</th>\n","      <td>140.0</td>\n","      <td>192.277599</td>\n","    </tr>\n","    <tr>\n","      <th>67</th>\n","      <td>170.0</td>\n","      <td>219.174948</td>\n","    </tr>\n","    <tr>\n","      <th>68</th>\n","      <td>145.0</td>\n","      <td>241.654051</td>\n","    </tr>\n","    <tr>\n","      <th>69</th>\n","      <td>200.0</td>\n","      <td>298.443787</td>\n","    </tr>\n","    <tr>\n","      <th>70</th>\n","      <td>273.0</td>\n","      <td>365.570457</td>\n","    </tr>\n","    <tr>\n","      <th>71</th>\n","      <td>300.0</td>\n","      <td>402.318557</td>\n","    </tr>\n","    <tr>\n","      <th>72</th>\n","      <td>5.9</td>\n","      <td>-250.771870</td>\n","    </tr>\n","    <tr>\n","      <th>73</th>\n","      <td>32.0</td>\n","      <td>-91.487008</td>\n","    </tr>\n","    <tr>\n","      <th>74</th>\n","      <td>40.0</td>\n","      <td>-38.541628</td>\n","    </tr>\n","    <tr>\n","      <th>75</th>\n","      <td>51.5</td>\n","      <td>19.850421</td>\n","    </tr>\n","    <tr>\n","      <th>76</th>\n","      <td>70.0</td>\n","      <td>24.772853</td>\n","    </tr>\n","    <tr>\n","      <th>77</th>\n","      <td>100.0</td>\n","      <td>58.209999</td>\n","    </tr>\n","    <tr>\n","      <th>78</th>\n","      <td>78.0</td>\n","      <td>80.138449</td>\n","    </tr>\n","    <tr>\n","      <th>79</th>\n","      <td>80.0</td>\n","      <td>90.611112</td>\n","    </tr>\n","    <tr>\n","      <th>80</th>\n","      <td>85.0</td>\n","      <td>92.293575</td>\n","    </tr>\n","    <tr>\n","      <th>81</th>\n","      <td>85.0</td>\n","      <td>101.295452</td>\n","    </tr>\n","    <tr>\n","      <th>82</th>\n","      <td>110.0</td>\n","      <td>135.985675</td>\n","    </tr>\n","    <tr>\n","      <th>83</th>\n","      <td>115.0</td>\n","      <td>136.790436</td>\n","    </tr>\n","    <tr>\n","      <th>84</th>\n","      <td>125.0</td>\n","      <td>138.513922</td>\n","    </tr>\n","    <tr>\n","      <th>85</th>\n","      <td>130.0</td>\n","      <td>163.122027</td>\n","    </tr>\n","    <tr>\n","      <th>86</th>\n","      <td>120.0</td>\n","      <td>171.287250</td>\n","    </tr>\n","    <tr>\n","      <th>87</th>\n","      <td>120.0</td>\n","      <td>160.628108</td>\n","    </tr>\n","    <tr>\n","      <th>88</th>\n","      <td>130.0</td>\n","      <td>173.927864</td>\n","    </tr>\n","    <tr>\n","      <th>89</th>\n","      <td>135.0</td>\n","      <td>167.277986</td>\n","    </tr>\n","    <tr>\n","      <th>90</th>\n","      <td>110.0</td>\n","      <td>167.865624</td>\n","    </tr>\n","    <tr>\n","      <th>91</th>\n","      <td>130.0</td>\n","      <td>182.366315</td>\n","    </tr>\n","    <tr>\n","      <th>92</th>\n","      <td>150.0</td>\n","      <td>208.852636</td>\n","    </tr>\n","    <tr>\n","      <th>93</th>\n","      <td>145.0</td>\n","      <td>190.612106</td>\n","    </tr>\n","    <tr>\n","      <th>94</th>\n","      <td>150.0</td>\n","      <td>177.772822</td>\n","    </tr>\n","    <tr>\n","      <th>95</th>\n","      <td>170.0</td>\n","      <td>223.294953</td>\n","    </tr>\n","    <tr>\n","      <th>96</th>\n","      <td>225.0</td>\n","      <td>265.457832</td>\n","    </tr>\n","    <tr>\n","      <th>97</th>\n","      <td>145.0</td>\n","      <td>241.773140</td>\n","    </tr>\n","    <tr>\n","      <th>98</th>\n","      <td>188.0</td>\n","      <td>272.752538</td>\n","    </tr>\n","    <tr>\n","      <th>99</th>\n","      <td>180.0</td>\n","      <td>267.220590</td>\n","    </tr>\n","    <tr>\n","      <th>100</th>\n","      <td>197.0</td>\n","      <td>295.891086</td>\n","    </tr>\n","    <tr>\n","      <th>101</th>\n","      <td>218.0</td>\n","      <td>369.565140</td>\n","    </tr>\n","    <tr>\n","      <th>102</th>\n","      <td>300.0</td>\n","      <td>411.502604</td>\n","    </tr>\n","    <tr>\n","      <th>103</th>\n","      <td>260.0</td>\n","      <td>366.126641</td>\n","    </tr>\n","    <tr>\n","      <th>104</th>\n","      <td>265.0</td>\n","      <td>362.855467</td>\n","    </tr>\n","    <tr>\n","      <th>105</th>\n","      <td>250.0</td>\n","      <td>374.593643</td>\n","    </tr>\n","    <tr>\n","      <th>106</th>\n","      <td>250.0</td>\n","      <td>395.072084</td>\n","    </tr>\n","    <tr>\n","      <th>107</th>\n","      <td>300.0</td>\n","      <td>435.575171</td>\n","    </tr>\n","    <tr>\n","      <th>108</th>\n","      <td>320.0</td>\n","      <td>443.591862</td>\n","    </tr>\n","    <tr>\n","      <th>109</th>\n","      <td>514.0</td>\n","      <td>620.344963</td>\n","    </tr>\n","    <tr>\n","      <th>110</th>\n","      <td>556.0</td>\n","      <td>644.929996</td>\n","    </tr>\n","    <tr>\n","      <th>111</th>\n","      <td>840.0</td>\n","      <td>716.129670</td>\n","    </tr>\n","    <tr>\n","      <th>112</th>\n","      <td>685.0</td>\n","      <td>712.401600</td>\n","    </tr>\n","    <tr>\n","      <th>113</th>\n","      <td>700.0</td>\n","      <td>725.520568</td>\n","    </tr>\n","    <tr>\n","      <th>114</th>\n","      <td>700.0</td>\n","      <td>713.933165</td>\n","    </tr>\n","    <tr>\n","      <th>115</th>\n","      <td>690.0</td>\n","      <td>717.912893</td>\n","    </tr>\n","    <tr>\n","      <th>116</th>\n","      <td>900.0</td>\n","      <td>803.687332</td>\n","    </tr>\n","    <tr>\n","      <th>117</th>\n","      <td>650.0</td>\n","      <td>770.193116</td>\n","    </tr>\n","    <tr>\n","      <th>118</th>\n","      <td>820.0</td>\n","      <td>846.270847</td>\n","    </tr>\n","    <tr>\n","      <th>119</th>\n","      <td>850.0</td>\n","      <td>809.693402</td>\n","    </tr>\n","    <tr>\n","      <th>120</th>\n","      <td>900.0</td>\n","      <td>807.169159</td>\n","    </tr>\n","    <tr>\n","      <th>121</th>\n","      <td>1015.0</td>\n","      <td>833.822861</td>\n","    </tr>\n","    <tr>\n","      <th>122</th>\n","      <td>820.0</td>\n","      <td>783.196139</td>\n","    </tr>\n","    <tr>\n","      <th>123</th>\n","      <td>1100.0</td>\n","      <td>880.140869</td>\n","    </tr>\n","    <tr>\n","      <th>124</th>\n","      <td>1000.0</td>\n","      <td>890.724522</td>\n","    </tr>\n","    <tr>\n","      <th>125</th>\n","      <td>1100.0</td>\n","      <td>920.257727</td>\n","    </tr>\n","    <tr>\n","      <th>126</th>\n","      <td>1000.0</td>\n","      <td>927.610354</td>\n","    </tr>\n","    <tr>\n","      <th>127</th>\n","      <td>1000.0</td>\n","      <td>947.516165</td>\n","    </tr>\n","    <tr>\n","      <th>128</th>\n","      <td>200.0</td>\n","      <td>383.563510</td>\n","    </tr>\n","    <tr>\n","      <th>129</th>\n","      <td>300.0</td>\n","      <td>412.932325</td>\n","    </tr>\n","    <tr>\n","      <th>130</th>\n","      <td>300.0</td>\n","      <td>451.291299</td>\n","    </tr>\n","    <tr>\n","      <th>131</th>\n","      <td>300.0</td>\n","      <td>539.966400</td>\n","    </tr>\n","    <tr>\n","      <th>132</th>\n","      <td>430.0</td>\n","      <td>599.581488</td>\n","    </tr>\n","    <tr>\n","      <th>133</th>\n","      <td>345.0</td>\n","      <td>574.212030</td>\n","    </tr>\n","    <tr>\n","      <th>134</th>\n","      <td>456.0</td>\n","      <td>699.687280</td>\n","    </tr>\n","    <tr>\n","      <th>135</th>\n","      <td>510.0</td>\n","      <td>689.879591</td>\n","    </tr>\n","    <tr>\n","      <th>136</th>\n","      <td>540.0</td>\n","      <td>726.408225</td>\n","    </tr>\n","    <tr>\n","      <th>137</th>\n","      <td>500.0</td>\n","      <td>739.348570</td>\n","    </tr>\n","    <tr>\n","      <th>138</th>\n","      <td>567.0</td>\n","      <td>810.288812</td>\n","    </tr>\n","    <tr>\n","      <th>139</th>\n","      <td>770.0</td>\n","      <td>832.640293</td>\n","    </tr>\n","    <tr>\n","      <th>140</th>\n","      <td>950.0</td>\n","      <td>966.667240</td>\n","    </tr>\n","    <tr>\n","      <th>141</th>\n","      <td>1250.0</td>\n","      <td>1103.888589</td>\n","    </tr>\n","    <tr>\n","      <th>142</th>\n","      <td>1600.0</td>\n","      <td>1152.752481</td>\n","    </tr>\n","    <tr>\n","      <th>143</th>\n","      <td>1550.0</td>\n","      <td>1152.752481</td>\n","    </tr>\n","    <tr>\n","      <th>144</th>\n","      <td>1650.0</td>\n","      <td>1265.843019</td>\n","    </tr>\n","    <tr>\n","      <th>145</th>\n","      <td>6.7</td>\n","      <td>-224.382326</td>\n","    </tr>\n","    <tr>\n","      <th>146</th>\n","      <td>7.5</td>\n","      <td>-199.398436</td>\n","    </tr>\n","    <tr>\n","      <th>147</th>\n","      <td>7.0</td>\n","      <td>-200.969515</td>\n","    </tr>\n","    <tr>\n","      <th>148</th>\n","      <td>9.7</td>\n","      <td>-178.047479</td>\n","    </tr>\n","    <tr>\n","      <th>149</th>\n","      <td>9.8</td>\n","      <td>-177.758950</td>\n","    </tr>\n","    <tr>\n","      <th>150</th>\n","      <td>8.7</td>\n","      <td>-180.772783</td>\n","    </tr>\n","    <tr>\n","      <th>151</th>\n","      <td>10.0</td>\n","      <td>-160.733438</td>\n","    </tr>\n","    <tr>\n","      <th>152</th>\n","      <td>9.9</td>\n","      <td>-163.383041</td>\n","    </tr>\n","    <tr>\n","      <th>153</th>\n","      <td>9.8</td>\n","      <td>-162.017600</td>\n","    </tr>\n","    <tr>\n","      <th>154</th>\n","      <td>12.2</td>\n","      <td>-160.608116</td>\n","    </tr>\n","    <tr>\n","      <th>155</th>\n","      <td>13.4</td>\n","      <td>-145.535439</td>\n","    </tr>\n","    <tr>\n","      <th>156</th>\n","      <td>12.2</td>\n","      <td>-137.843413</td>\n","    </tr>\n","    <tr>\n","      <th>157</th>\n","      <td>19.7</td>\n","      <td>-83.279758</td>\n","    </tr>\n","    <tr>\n","      <th>158</th>\n","      <td>19.9</td>\n","      <td>-82.005694</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a87215cb-55d9-4ee7-8ef0-79020e33666d')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-a87215cb-55d9-4ee7-8ef0-79020e33666d button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-a87215cb-55d9-4ee7-8ef0-79020e33666d');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["# Inserting Ridge regression\n","ridge = Ridge(normalize=True)\n","search = GridSearchCV(estimator=ridge,param_grid={'alpha':np.logspace(-5,2,8)},scoring='neg_mean_squared_error',n_jobs=1,refit=True,cv=10)\n","search.fit(X,y)\n","search.best_params_\n","{'alpha': 1.0}\n","abs(search.best_score_) \n","\n","# From the result, 22554.15 these indicate that there is little difference between the ridge and baseline models."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"adtq9OKBAP4r","executionInfo":{"status":"ok","timestamp":1650518508160,"user_tz":-180,"elapsed":1436,"user":{"displayName":"Brian Onyango","userId":"15608923775886601750"}},"outputId":"1c898280-05b8-4294-d45c-0b5b1c7bd83b"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n","/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n","If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n","\n","from sklearn.pipeline import make_pipeline\n","\n","model = make_pipeline(StandardScaler(with_mean=False), Ridge())\n","\n","If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n","\n","kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n","model.fit(X, y, **kwargs)\n","\n","Set parameter alpha to: original_alpha * n_samples. \n","  FutureWarning,\n"]},{"output_type":"execute_result","data":{"text/plain":["22554.158128353116"]},"metadata":{},"execution_count":16}]},{"cell_type":"markdown","metadata":{"id":"3-BreaBg2FdS"},"source":["### <font color=\"green\">Challenge 2</font>"]},{"cell_type":"code","metadata":{"id":"LwOJURwR2G0Q"},"source":["# Challenge 2\n","# ---\n","# Question: Build a regression algorithm for predicting unemployment within an economy.\n","# ---\n","# Dataset url = http://bit.ly/EconomicDataset\n","# ---\n","# Dataset Info\n","# 1. date. Month of data collection\n","# 2. psavert, personal savings rate\n","# 3. pce, personal consumption expenditures, in billions of dollars\n","# 4. unemploy, number of unemployed in thousands \n","# 5. empmed, median duration of unemployment, in week\n","# 6. pop, total population, in thousands\n","# ---\n","# \n","OUR CODE GOES HERE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AMM6ePT52H0Z"},"source":["### <font color=\"green\">Challenge 3</font>"]},{"cell_type":"code","metadata":{"id":"vUGrmjzy2JDy"},"source":["# Challenge 3\n","# ---\n","# Question: Build a regression model to predict the life expectancy of a country. \n","# Apply ridge regression to your model.\n","# ---\n","# Dataset url = http://bit.ly/LifeExpectancyDataset\n","# ---\n","# Dataset Info:\n","# Country: Country\n","# Year: Year\n","# Status: Developed or Developing status\n","# Life expectancy: Life Expectancy in age\n","# Adult Mortality: Adult Mortality Rates of both sexes (probability of dying between 15 and 60 years per 1000 population)\n","# infant deaths: Number of Infant Deaths per 1000 population\n","# Alcohol: Alcohol, recorded per capita (15+) consumption (in litres of pure alcohol)\n","# percentage expenditure: Expenditure on health as a percentage of Gross Domestic Product per capita(%)\n","# Hepatitis B: Hepatitis B (HepB) immunization coverage among 1-year-olds (%)\n","# Measles: Measles: number of reported cases per 1000 population\n","# BMI: Average Body Mass Index of entire population\n","# under-five: deaths Number of under-five deaths per 1000 population\n","# Polio: Polio (Pol3) immunization coverage among 1-year-olds (%)\n","# Total expenditure: General government expenditure on health as a percentage of total government expenditure (%)\n","# Diphtheria: Diphtheria tetanus toxoid and pertussis (DTP3) immunization coverage among 1-year-olds (%)\n","# HIV/AIDS: Deaths per 1 000 live births HIV/AIDS (0-4 years)\n","# GDP: Gross Domestic Product per capita (in USD)\n","# Population: Population of the country\n","# thinness 1-19 years: Prevalence of thinness among children and adolescents for Age 10 to 19 (% )\n","# thinness 5-9 years: Prevalence of thinness among children for Age 5 to 9(%)\n","# Income composition of resources: Human Development Index in terms of income composition of resources (index ranging from 0 to 1)\n","# Schooling: Number of years of Schooling(years)\n","# ---\n","# \n","OUR CODE GOES HERE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CfPAQs0M2Jwi"},"source":["### <font color=\"green\">Challenge 4</font>"]},{"cell_type":"code","metadata":{"id":"2E00VHOX2LwW"},"source":["# Challenge 4\n","# ---\n","# Question: Given the beauty dataset below, create a regression model to predict wages upon applying ridge regression.\n","# ---\n","# Dataset url = http://bit.ly/BeautyDataset\n","# ---\n","# \n","OUR CODE GOES HERE"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0-cyo-cG2MOs"},"source":["### <font color=\"green\">Challenge 5</font>"]},{"cell_type":"code","metadata":{"id":"G8WSyCrz2N_6"},"source":["# Challenge 5\n","# ---\n","# Create a regression model to predict sales prices. \n","# Apply regularization techniques.\n","# ---\n","# Dataset source = http://bit.ly/HousePricesDataset\n","# ---\n","# \n","OUR CODE GOES HERE"],"execution_count":null,"outputs":[]}]}